# paper-repository
## Semi-Supervised Learning
2023-NeurIPS-__S-CLIP: Semi-supervised Vision-Language Learning using Few Specialist Captions__ [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/c06f788963f0ce069f5b2dbf83fe7822-Paper-Conference.pdf)] [[code](https://proceedings.neurips.cc/paper_files/paper/2023/file/c06f788963f0ce069f5b2dbf83fe7822-Paper-Conference.pdf)]  
2024-NeurIPS-__OwMatch: Conditional Self-Labeling with Consistency for Open-World Semi-Supervised Learning__ [[paper](https://proceedings.neurips.cc/paper_files/paper/2024/file/b4fd162d3e2d015233486a2e313828a7-Paper-Conference.pdf)] [[code](https://github.com/niusj03/OwMatch)]  
2024-ICML-__Candidate Pseudolabel Learning: Enhancing Vision-Language Models by Prompt Tuning with Unlabeled Data__[[paper](https://arxiv.org/pdf/2406.10502)] [[code](https://github.com/vanillaer/CPL-ICML2024)]  
2025-ICLR-__SEMI-SUPERVISED CLIP ADAPTATION BY ENFORCING SEMANTIC AND TRAPEZOIDAL CONSISTENCY__[[paper](https://openreview.net/pdf?id=97D725GJtQ)] [[code](https://github.com/Gank0078/SemiCLIP)]  
2025-CVPR-__Language-Assisted Debiasing and Smoothing for Foundation Model-Based Semi-Supervised Learning__  
2025-CVPR-__Towards Cost-Effective Learning: A Synergy of Semi-Supervised and Active Learning__  
2025-CVPR-__Seek Common Ground While Reserving Differences: Semi-supervised Image-Text Sentiment Recognition__  
2025-CVPR-__CLIP-driven Coarse-to-fine Semantic Guidance for Fine-grained Open-set Semi-supervised Learning__  
2025-CVPR-__Learning Textual Prompts for Open-World Semi-Supervised Learning__  
2025-CVPR-__Seek Common Ground While Reserving Differences: Semi-supervised Image-Text Sentiment Recognition__  
2024-Arxiv-__DPA: Dual Prototypes Alignment for Unsupervised Adaptation of Vision-Language Models__[[paper](https://arxiv.org/pdf/2408.08855?)]  
2024-Arxiv-__FINESSL:Erasing the Bias: Fine-Tuning Foundation Models for Semi-Supervised Learning__ [[paper](https://arxiv.org/pdf/2405.11756)] [[code](https://github.com/Gank0078/FineSSL)]  
2025-Arxiv-__Revisiting Semi-Supervised Learning in the Era of Foundation Models__ [[paper](https://arxiv.org/pdf/2503.09707)] [[code](https://github.com/OSU-MLB/SSL-Foundation-Models)]  
2025-Arxiv-__CGMatch: A Different Perspective of Semi-supervised Learning__[[paper](https://arxiv.org/pdf/2503.02231?)] [[code](https://github.com/BoCheng-96/CGMatch)]  
2025-Arxiv-__SelfPrompt: Confidence-Aware Semi-Supervised Tuning for Robust Vision-Language Model Adaptation__[[paper](https://arxiv.org/pdf/2501.14148)]  

## Foundation model Fine-tuning
2024-NeurIPS-__Boosting Vision-Language Models with Transduction__ [[paper](https://proceedings.neurips.cc/paper_files/paper/2024/file/71d7dbe2652bd4662d29fa269f059db4-Paper-Conference.pdf)] [[code](https://github.com/MaxZanella/transduction-for-vlms)]  
2025-Arxiv-__COSMIC:Clique-Oriented Semantic Multi-space Integration for Robust CLIP Test-Time Adaptation__ [[paper](https://arxiv.org/pdf/2503.23388)] [[code](https://github.com/hf618/COSMIC)]  
2025-Arxiv-__GET: Unlocking the Multi-modal Potential of CLIP for Generalized Category Discovery__ [[paper](https://arxiv.org/pdf/2403.09974)] [[code](https://github.com/enguangW/GET)]  
## Medical
2024-Nature-__A pathology foundation model for cancer diagnosis and prognosis prediction__  
2025-Nature-__A vision–language foundation model for precision oncology__  
2024-LNCS-__Boosting Vision-Language Models for Histopathology Classification: Predict all at once__ [[paper](https://arxiv.org/pdf/2409.01883)] [[code](https://github.com/FereshteShakeri/Histo-TransCLIP)]  
2024-CVPR-__ViLa-MIL: Dual-scale Vision-Language Multiple Instance Learning for Whole Slide Image Classification__ [[paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Shi_ViLa-MIL_Dual-scale_Vision-Language_Multiple_Instance_Learning_for_Whole_Slide_Image_CVPR_2024_paper.pdf)] [[code](https://github.com/Jiangbo-Shi/ViLa-MIL)]  
2024-CVPR-__Generalizable whole slide image classification with fine-grained visual-semantic interaction__ [[paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Li_Generalizable_Whole_Slide_Image_Classification_with_Fine-Grained_Visual-Semantic_Interaction_CVPR_2024_paper.pdf)] [[code](https://github.com/ls1rius/WSI_FIVE)]  
2024-CVPR-__CPLIP: Zero-Shot Learning for Histopathology with Comprehensive Vision-Language Alignment__ [[paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Javed_CPLIP_Zero-Shot_Learning_for_Histopathology_with_Comprehensive_Vision-Language_Alignment_CVPR_2024_paper.pdf)] [[code](https://github.com/iyyakuttiiyappan/CPLIP)]  






