# paper-repository
## Semi-Supervised Learning
2023-NeurIPS-__S-CLIP: Semi-supervised Vision-Language Learning using Few Specialist Captions__ [[paper](https://proceedings.neurips.cc/paper_files/paper/2023/file/c06f788963f0ce069f5b2dbf83fe7822-Paper-Conference.pdf)] [[code](https://proceedings.neurips.cc/paper_files/paper/2023/file/c06f788963f0ce069f5b2dbf83fe7822-Paper-Conference.pdf)]  
2024-NeurIPS-__OwMatch: Conditional Self-Labeling with Consistency for Open-World Semi-Supervised Learning__ [[paper](https://proceedings.neurips.cc/paper_files/paper/2024/file/b4fd162d3e2d015233486a2e313828a7-Paper-Conference.pdf)] [[code](https://github.com/niusj03/OwMatch)]  
2024-Arxiv-__DPA: Dual Prototypes Alignment for Unsupervised Adaptation of Vision-Language Models__[[paper](https://arxiv.org/pdf/2408.08855?)]  
2024-Arxiv-__FINESSL:Erasing the Bias: Fine-Tuning Foundation Models for Semi-Supervised Learning__ [[paper](https://arxiv.org/pdf/2405.11756)] [[code](https://github.com/Gank0078/FineSSL)]  
2024-ICML-__Candidate Pseudolabel Learning: Enhancing Vision-Language Models by Prompt Tuning with Unlabeled Data__[[paper](https://arxiv.org/pdf/2406.10502)] [[code](https://github.com/vanillaer/CPL-ICML2024)]  
2025-ICLR-__SEMI-SUPERVISED CLIP ADAPTATION BY ENFORCING SEMANTIC AND TRAPEZOIDAL CONSISTENCY__[[paper](https://openreview.net/pdf?id=97D725GJtQ)] [[code](https://github.com/Gank0078/SemiCLIP)]  
2025-CVPR-__Language-Assisted Debiasing and Smoothing for Foundation Model-Based Semi-Supervised Learning__  
2025-CVPR-__Towards Cost-Effective Learning: A Synergy of Semi-Supervised and Active Learning__  
2025-CVPR-__Seek Common Ground While Reserving Differences: Semi-supervised Image-Text Sentiment Recognition__  
2025-CVPR-__CLIP-driven Coarse-to-fine Semantic Guidance for Fine-grained Open-set Semi-supervised Learning__  
2025-CVPR-__Learning Textual Prompts for Open-World Semi-Supervised Learning__  
2025-CVPR-__Seek Common Ground While Reserving Differences: Semi-supervised Image-Text Sentiment Recognition__  
2025-Arxiv-__Revisiting Semi-Supervised Learning in the Era of Foundation Models__ [[paper](https://arxiv.org/pdf/2503.09707)] [[code](https://github.com/OSU-MLB/SSL-Foundation-Models)]  
2025-Arxiv-__CGMatch: A Different Perspective of Semi-supervised Learning__[[paper](https://arxiv.org/pdf/2503.02231?)] [[code](https://github.com/BoCheng-96/CGMatch)]  
2025-Arxiv-__SelfPrompt: Confidence-Aware Semi-Supervised Tuning for Robust Vision-Language Model Adaptation__[[paper](https://arxiv.org/pdf/2501.14148)]  

## Foundation model Fine-tuning
2024-NeurIPS-__Boosting Vision-Language Models with Transduction__ [[paper](https://proceedings.neurips.cc/paper_files/paper/2024/file/71d7dbe2652bd4662d29fa269f059db4-Paper-Conference.pdf)] [[code](https://github.com/MaxZanella/transduction-for-vlms)]  
2025-CVPR-__COSMIC:Clique-Oriented Semantic Multi-space Integration for Robust CLIP Test-Time Adaptation__ [[paper](https://arxiv.org/pdf/2503.23388)] [[code](https://github.com/hf618/COSMIC)]  
2025-CVPR-__GET: Unlocking the Multi-modal Potential of CLIP for Generalized Category Discovery__ [[paper](https://arxiv.org/pdf/2403.09974)] [[code](https://github.com/enguangW/GET)]  
## Medical
### VLM, Multimodal, Zero-shot
2023-Arxiv-__Foundation Models in Computational Pathology: A Review of Challenges, Opportunities, and Impact__ [[paper](https://arxiv.org/pdf/2502.08333)] 
2024-Nature-__A pathology foundation model for cancer diagnosis and prognosis prediction__  
2024-LNCS-__Boosting Vision-Language Models for Histopathology Classification: Predict all at once__ [[paper](https://arxiv.org/pdf/2409.01883)] [[code](https://github.com/FereshteShakeri/Histo-TransCLIP)]  
2024-ECCV-__Knowledge-enhanced visual-language pretraining for computational pathology__ [[paper](https://arxiv.org/pdf/2404.09942)] [[code](https://github.com/MAGIC-AI4Med/KEP)]  
2024-CVPR-__CPLIP: Zero-Shot Learning for Histopathology with Comprehensive Vision-Language Alignment__ [[paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Javed_CPLIP_Zero-Shot_Learning_for_Histopathology_with_Comprehensive_Vision-Language_Alignment_CVPR_2024_paper.pdf)] [[code](https://github.com/iyyakuttiiyappan/CPLIP)]  
2025-CVPR-__CPath-Omni: A Unified Multimodal Foundation Model for Patch and Whole Slide Image Analysis in Computational Pathology__ [[paper](https://arxiv.org/pdf/2412.12077)]  
2025-Nature-__BEPH:A foundation model for generalizable cancer diagnosis and survival prediction from histopathological images__  [[paper](https://www.nature.com/articles/s41467-025-57587-y#Sec10)] [[code](https://github.com/Zhcyoung/BEPH)]  
2025-Nature-__A vision–language foundation model for precision oncology__[[paper](https://www.nature.com/articles/s41586-024-08378-w#code-availability)]  
2025-Arxiv-__GECKO:GigapixelVision-Concept Contrastive Pretraining in Histopathology__ [[paper](https://arxiv.org/pdf/2504.01009)] [[code](https://github.com/bmi-imaginelab/GECKO)]  
2025-Arxiv-__BiomedCoOp: Learning to Prompt for Biomedical Vision-Language Models__ [[paper](https://arxiv.org/pdf/2411.15232)] [[code](https://github.com/HealthX-Lab/BiomedCoOp)]  
2025-Arxiv-__Unsupervised Foundation Model-Agnostic Slide-Level Representation Learning__ [[paper](https://arxiv.org/pdf/2411.13623)] [[code](https://github.com/KatherLab/COBRA)]  
### others
2024-MICCAI-__Hierarchical text-to-vision self supervised alignment for improved histopathology representation learning__ [[paper](https://link.springer.com/chapter/10.1007/978-3-031-72083-3_16)] [[code](https://github.com/Hasindri/HLSS)]  
2024-CVPR-__ViLa-MIL: Dual-scale Vision-Language Multiple Instance Learning for Whole Slide Image Classification__ [[paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Shi_ViLa-MIL_Dual-scale_Vision-Language_Multiple_Instance_Learning_for_Whole_Slide_Image_CVPR_2024_paper.pdf)] [[code](https://github.com/Jiangbo-Shi/ViLa-MIL)]  
2024-CVPR-__Generalizable whole slide image classification with fine-grained visual-semantic interaction__ [[paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Li_Generalizable_Whole_Slide_Image_Classification_with_Fine-Grained_Visual-Semantic_Interaction_CVPR_2024_paper.pdf)] [[code](https://github.com/ls1rius/WSI_FIVE)]  
2025-ICLR-__Interpretable Vision-Language Survival Analysis with Ordinal Inductive Bias for Computational Pathology__ [[paper](https://arxiv.org/pdf/2409.09369)] [[code](https://github.com/liupei101/VLSA)]  
2025-CVPR-__FOCUS: Knowledge-enhanced Adaptive Visual Compression for Few-shot Whole Slide Image Classification__ [[paper](https://arxiv.org/pdf/2411.14743)] [[code](https://github.com/dddavid4real/FOCUS)]  
2025-CVPR-__No Pains, More Gains: Recycling Sub-Salient Patches for Efficient High-Resolution Image Recognition__  
2025-CVPR-__MExD:AnExpert-InfusedDiffusionModelforWhole-SlideImageClassification__[[paper](https://arxiv.org/pdf/2503.12401)] [[code](https://github.com/JWZhao-uestc/MExD)]  
2025-CVPR-__MERGE:Multi-faceted Hierarchical Graph-based GNN for Gene Expression Prediction from Whole Slide Histopathology Images__ [[paper](https://arxiv.org/pdf/2412.02601)]  
2025-CVPR-__WISE: AFramework for Gigapixel Whole-Slide-Image Lossless Compression__ [[paper](https://arxiv.org/pdf/2503.18074)]  
2025-CVPR-__Prototype-Based Image Prompting for Weakly Supervised Histopathological Image Segmentation__[[paper](https://arxiv.org/pdf/2503.12068)] [[code](https://github.com/QingchenTang/PBIP)]  
2025-CVPR-__Fast and Accurate Gigapixel Pathological Image Classification with Hierarchical Distillation Multi-Instance Learning__ [[paper](https://arxiv.org/pdf/2502.21130)] [[code](https://github.com/JiuyangDong/HDMIL)]  
2025-CVPR-__2DMamba: Efficient State Space Model for Image Representation with Applications on Giga-Pixel Whole Slide Image Classification__  
2025-CVPR-__M3amba: Memory Mamba is All You Need for Whole Slide Image Classification__  
2025-CVPR-__Learning Heterogeneous Tissues with Mixture of Experts for Gigapixel Whole Slide Images__  
2025-CVPR-__Advancing Multiple Instance Learning with Continual Learning for Whole Slide Imaging__  
2025-CVPR-__SlideChat: A Large Vision-Language Assistant for Whole-Slide Pathology Image Understanding__  
2025-CVPR-__Multi-Resolution Pathology-Language Pre-training Model with Text-Guided Visual Representation__  
2025-CVPR-__Multi-modal Topology-embedded Graph Learning for Spatially Resolved Genes Prediction from Pathology Images with Prior Gene Similarity Information__  
2025-Arxiv-__Unsupervised Foundation Model-Agnostic Slide-Level Representation Learning__ [[paper](https://arxiv.org/pdf/2411.13623)] [[code](https://github.com/KatherLab/COBRA)]  
2025-Arxiv-__Multi-ModalFoundationModelsforComputationalPathology:A Survey__ [[paper](https://arxiv.org/pdf/2503.09091)]  
2025-Arxiv-__Label-free Concept Based Multiple Instance Learning for Gigapixel Histopathology__ [[paper](https://arxiv.org/pdf/2501.02922)] [[code](https://github.com/ss-sun/ConceptMIL)]  


## Mixture of Experts 
2024-NIPS-__MoVA: Adapting Mixture of Vision Experts to Multimodal Context__ [[paper](https://arxiv.org/pdf/2404.13046?)] [[code](https://github.com/TempleX98/MoVA)]













